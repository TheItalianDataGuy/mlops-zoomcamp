{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20517be3-7195-4b93-be6c-377ecf214ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148f3e07-b7e1-4327-95cd-37da300bcc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         14.30                   2.5         0.00  \n",
       "1                    1.0         16.90                   2.5         0.00  \n",
       "2                    1.0         34.90                   2.5         0.00  \n",
       "3                    1.0         20.85                   0.0         1.25  \n",
       "4                    1.0         19.68                   2.5         0.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413fcb6d-51ca-4cf5-a6d7-0fbb0ef41a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. Downloading the data\n",
    "# We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "# Read the data for January. How many columns are there?\n",
    "\n",
    "len(df.columns) # 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c151cc-e61e-4664-8f4d-78ac491e8033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.59435124195458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2. Computing duration\n",
    "# Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "# What's the standard deviation of the trips duration in January?\n",
    "\n",
    "\n",
    "df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "df['duration'] = df['duration'].dt.total_seconds() / 60\n",
    "df['duration'].std() # 42.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c84e8e-f3d3-427a-af68-b8d5db1bd888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'98.1220282212598%'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3. Dropping outliers\n",
    "# Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "# What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "df_filtered = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "\n",
    "fraction = f'{(len(df_filtered) / len(df)) * 100}%'\n",
    "fraction # 98.12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86df8ac0-58d4-4a10-96c4-c8c4dc797dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/qr7lg_zn25990k8pbb594l4c0000gn/T/ipykernel_68481/2009368799.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['pickup_ids'] = df_filtered['PULocationID'].astype(str)\n",
      "/var/folders/rn/qr7lg_zn25990k8pbb594l4c0000gn/T/ipykernel_68481/2009368799.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['dropoff_ids'] = df_filtered['DOLocationID'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3009173, 515)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4. One-hot encoding\n",
    "# Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "# Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "# Fit a dictionary vectorizer. Get a feature matrix from it.\n",
    "# What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "df_filtered['pickup_ids'] = df_filtered['PULocationID'].astype(str)\n",
    "df_filtered['dropoff_ids'] = df_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "df_dict = df_filtered[['pickup_ids', 'dropoff_ids']].to_dict(orient='records')\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "matrix = dv.fit_transform(df_dict)\n",
    "matrix.shape  # 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6f5f61-1689-4999-a209-643d348c5aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.649261927686161"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5. Training a model\n",
    "# Now let's use the feature matrix from the previous step to train a model.\n",
    "# Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "# Calculate the RMSE of the model on the training data\n",
    "# What's the RMSE on train?\n",
    "\n",
    "X_train = matrix\n",
    "y_train = df_filtered['duration'].values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "rmse = mean_squared_error(y_train, y_pred) # it does not accept the argument 'squared' so I use numpy to do that!\n",
    "rmse = np.sqrt(rmse) \n",
    "rmse # 7.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f103d8cb-5c3e-412e-8488-4901ba161608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/qr7lg_zn25990k8pbb594l4c0000gn/T/ipykernel_68481/3518020768.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feb_filtered['pickup_ids'] = df_feb_filtered['PULocationID'].astype(str)\n",
      "/var/folders/rn/qr7lg_zn25990k8pbb594l4c0000gn/T/ipykernel_68481/3518020768.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feb_filtered['dropoff_ids'] = df_feb_filtered['DOLocationID'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.811817957524739"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6. Evaluating the model\n",
    "# Now let's apply this model to the validation dataset (February 2023).\n",
    "# What's the RMSE on validation?\n",
    "\n",
    "df_feb = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "df_feb['duration'] = df_feb['tpep_dropoff_datetime'] - df_feb['tpep_pickup_datetime']\n",
    "df_feb['duration'] = df_feb['duration'].dt.total_seconds() / 60\n",
    "\n",
    "df_feb_filtered = df_feb[(df_feb['duration'] >= 1) & (df_feb['duration'] <= 60)]\n",
    "\n",
    "df_feb_filtered['pickup_ids'] = df_feb_filtered['PULocationID'].astype(str)\n",
    "df_feb_filtered['dropoff_ids'] = df_feb_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "df_feb_dict = df_feb_filtered[['pickup_ids', 'dropoff_ids']].to_dict(orient='records')\n",
    "\n",
    "X_feb = dv.transform(df_feb_dict)\n",
    "y_val = df_feb_filtered['duration'].values\n",
    "y_pred = lr.predict(X_feb)\n",
    "\n",
    "rmse_feb = mean_squared_error(y_pred, y_val) # it does not accept the argument 'squared' so I use numpy to do that!\n",
    "rmse_feb = np.sqrt(rmse_feb)\n",
    "rmse_feb # 7.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ea47cf-9f67-4521-8088-c0487da1e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)\n",
    "\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebfedd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.247500973564958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. Notebook\n",
    "# We'll start with the same notebook we ended up with in homework 1. \n",
    "# We cleaned it a little bit and kept only the scoring part. You can find the initial notebook here.\n",
    "# Run this notebook for the March 2023 data.\n",
    "# What's the standard deviation of the predicted duration for this dataset?\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)\n",
    "\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')\n",
    "\n",
    "df['pickup_ids'] = df['PULocationID'].astype(str)\n",
    "df['dropoff_ids'] = df['DOLocationID'].astype(str)\n",
    "dicts = df[['pickup_ids', 'dropoff_ids']].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred.std() # 6.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39226e30-df54-480a-b9c7-0edeb5dc584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What's the size of the output file?\n",
    "\n",
    "year = 2023\n",
    "month = 3\n",
    "\n",
    "# Create a new column 'ride_id'\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "# Create a new DataFrame to hold only the output columns\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "# Copy the ride_id to the new DataFrame\n",
    "df_result['ride_id'] = df['ride_id']\n",
    "\n",
    "# Add the predicted duration values to the new DataFrame\n",
    "df_result['predicted_duration'] = y_pred\n",
    "\n",
    "# Define the output filename based on the year and month\n",
    "output_file = f'output_{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "# Save the result as a Parquet file using pyarrow\n",
    "# No compression, and we don't include the index in the file\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 65.5MB ~ 66MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32ac1131-1860-43dd-97ea-414ce67c00cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (2803037006.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter nbconvert --to script 04-deployment.ipynb\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "# Q3. Now let's turn the notebook into a script.\n",
    "# Which command you need to execute for that?\n",
    "\n",
    "jupyter nbconvert --to script 04-deployment.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491b360-ebb9-4719-b452-8cc94e248a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
